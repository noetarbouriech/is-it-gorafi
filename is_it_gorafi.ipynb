{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noetarbouriech/is-it-gorafi/blob/main/is_it_gorafi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4nB3bkEjSrP"
      },
      "source": [
        "# Is it Gorafi?\n",
        "\n",
        "Text classification model for recognizing Gorafi news articles by comparing with Figaro news article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yciq2TW2YfbE"
      },
      "source": [
        "## Dependencies installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vubfNrtshTK",
        "outputId": "4f3fcdd8-b691-4a8e-a5f8-6bff7ef8761e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'is-it-gorafi'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 12 (delta 3), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (12/12), 59.05 KiB | 491.00 KiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/noetarbouriech/is-it-gorafi.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BIfWAtNYRton",
        "outputId": "aed19605-de66-4ec0-982d-8e465b61e686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting optimum[exporters]\n",
            "  Downloading optimum-1.24.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum[exporters]) (2.5.1+cu124)\n",
            "Collecting onnx (from optimum[exporters])\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime (from optimum[exporters])\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from optimum[exporters]) (1.0.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[exporters]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[exporters]) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[exporters]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[exporters]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11->optimum[exporters])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[exporters]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[exporters]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum[exporters]) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->optimum[exporters]) (4.25.6)\n",
            "Collecting coloredlogs (from onnxruntime->optimum[exporters])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->optimum[exporters]) (25.2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->optimum[exporters]) (0.20.1+cu124)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->optimum[exporters])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum[exporters]) (3.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm->optimum[exporters]) (11.1.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.24.0-py3-none-any.whl (433 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, coloredlogs, onnxruntime, nvidia-cusolver-cu12, datasets, optimum, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed coloredlogs-15.0.1 datasets-3.3.2 dill-0.3.8 evaluate-0.4.3 humanfriendly-10.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.17.0 onnxruntime-1.20.1 optimum-1.24.0 xxhash-3.5.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers huggingface_hub evaluate scikit-learn optimum[exporters]\n",
        "!apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDi7RRuZYkZ6"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d3350fefd4141959be4cd3ea6a955e1",
            "038dd84879af49209f6665e793b3b829",
            "9e85525e5b4149e0b86b5f6cebb93704",
            "66cea97b103044de911babb847e8e136",
            "f5faf2217894402ca0165c9ca50ca00f",
            "7f5637fad4c84226896fe1504027851d",
            "4974304de9be4d7881f1b55ac60a2051",
            "795a6d5b67a94cdb8eb616b0b3e48311",
            "316b4fe38b244c95bee618976ebd3d9f",
            "e746325e7a624edb83eb05092bfbe1f5",
            "7403c689ec494344a26ad2fb20f6706c"
          ]
        },
        "id": "Ju__xE4PRPwk",
        "outputId": "43956673-1906-4e42-9d76-e2eb9fc86e70"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Geotrend/distilbert-base-en-fr-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='301' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [301/800 08:38 < 14:26, 0.58 it/s, Epoch 7.50/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.411489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.350016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.354100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.406253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.543961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.542046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.604932</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [800/800 23:22, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.411489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.350016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.354100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.406253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.543961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.542046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.604932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.736801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.685950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.694836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.734873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.770819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.763092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.767236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.778000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.788078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.792660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.797640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.801333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.801822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/318 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d3350fefd4141959be4cd3ea6a955e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Acheté dans une brocante au Mans en 2010, le tableau s’avère être un Modigliani\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Un «film coup de poing»:Le Mohicanmet tous les maux de la Corse à l’écran\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Jean-Pierre Pernaut sera inhumé dans un cercueil fabriqué à la main par le dernier petit artisan du Poitou\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Les cérémonies des Jeux olympiques récompensées, une Victoire de la musique hors-norme\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Présidentielle – Un premier sondage place Cthulhu au second tour\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Législatives – N’Golo Kanté toujours en tête des intentions de vote\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Expulsions – Le RN remercie Valérie Pécresse d’avoir relié Châtelet à Orly en seulement 25 minutes\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Budget : «Je voterai la censure», assure François Ruffin\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Parlement européen – Faute de présences, le siège de Jordan Bardella transformé en relais colis\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: La présence d’Alain Finkielkraut à Nuit Debout, un simple bizutage de l’Académie française\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: True\n",
            "Title: The Brutalist,Captain America,Prima la vita... Les films à voir ou à éviter cette semaine\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Drop shipping – Magali Berdah vend son âme au diable trois fois le prix d’achat\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: «On remarque tout de suite les chefs qui ont la technique» : à Liège, le concours de chefs d’orchestre repère les talents de demain\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Jean Castex dévoilera ce soir le nouveau protocole d’applaudissements aux soignants\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: «Mickey 17», une satire du trumpisme signée Bong Joon-ho à la Berlinale\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: « Emportée par ses paroles, je me suis sentie lourde » : immersion dans un concert sous hypnose\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Notre critique deLa Mer au loin: le raï, la petite musique de l’exil\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Emilia Pérezremporte le Goya du meilleur film européen\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Rachida Dati entend « rapprocher la politique de l’architecture des réalités locales »\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: «Nous avons besoin d'une immigration de travail», assume Éric Lombard\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Todd Haynes, président du jury de la Berlinale 2025, critique le gouvernement de Donald Trump\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Malgré la bataille entre Brad Pitt et Angelina Jolie, le business juteux du vin rosé de Miraval\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Pour mieux les combattre Gérald Darmanin demande aux élus RN d’arrêter d’être toujours d’accord avec lui\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Gabriel Attal surprend tout le monde en arrivant à Matignon en abaya\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Trahisons: les lésions dangereuses selon Harold Pinter\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Laurence Sailliet chez Hanouna – Les chroniqueurs télé inquiets que l’arrivée des politiques dans les émissions ne décrédibilise leur métier\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Les chômeurs devront être équipés dès la rentrée d’un collier électrique\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: UGC propose des places à 100 euros pour avoir un siège sans punaise de lit\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: L’éditorial de Laurence de Charette : «Mariage de clandestins, les maires faux coupables»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: La Fabrique du mensonge: les méthodes et les dessous de la propagande nazie\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Les députés En Marche proposent que le président de la république soit élu au suffrage universel direct par un cabinet de conseil\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: True\n",
            "Title: Selon un sondage, 17 Français ne seraient pas encore candidats à l’élection présidentielle\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Nouvelle polémique après qu’un polémiste a réagi à la dernière polémique du polémiste très polémique\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Box-office France : belle entrée en scène pourUn parfait inconnu\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: L’éditorial de Laurence de Charette : «Mariage de clandestins, les maires faux coupables»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Lors d’une randonnée en solitaire, Pascal Praud réussit à ne se couper que 10 fois la parole\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Pour Halloween, des Français veulent se faire peur au cinéma en allant voir le film 4 Zéros\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Budget 2025 : s’il avait été député, Fabien Roussel n’aurait pas voté la censure\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: En raison de fragilités inattendues, les tours de Notre-Dame de Paris ne rouvriront que cet été\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Jean Castex confirme la réouverture des restaurants à la mi-mai de 20h à 22h les soirs de pleine lune\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: La décrue de la Seine menace BFM TV de sujets de fond\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: France Inter – Guillaume Meurice remplacé dès dimanche par une sorte de nazi sans prépuce\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: La Diagonale du Figaro N°59 : «Pragg», l’intrépide vainqueur de Wijk aan Zee, le Wimbledon des échecs\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: En tête dans les sondages, l’abstention refuse toujours de déclarer sa candidature\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Déficit public : les explications d’Alexis Kohler pour refuser la convocation de la commission d’enquête de l’Assemblée\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Un électeur retrouvé 7 jours plus tard dans l’isoloir en train de finir de plier son bulletin de vote\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Les Gooniesauront finalement une suite 40 ans après\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: False\n",
            "Title: Pour tenter de contrer Zemmour médiatiquement, Yannick Jadot abat deux éléphants\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Il allume sa télévision et ne tombe pas sur Guillaume Canet en promo d’Astérix\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Paris – Emmanuel Macron fait jeter les derniers SDF dans la vasque olympique\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Covid19 – Emmanuel Macron signe un décret ordonnant que François Hollande soit vacciné tout en dernier\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: «Bruno, il faut que tu y ailles», les indiscrétions duFigaro Magazine\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Marine Le Pen a revendu un million d’euros un appartement légué par une sympathisante cannoise\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: False\n",
            "Title: Les députés valident l’obligation du pass sanitaire pour accéder aux manifestations contre le pass sanitaire\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: True\n",
            "Title: Cet article est réservé aux abonnés\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Manuel Valls en garde à vue pour ne pas avoir dit du bien d’Emmanuel Macron depuis trois jours\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Liberté d’expression: Un rapport démontre que ******* et ***** pour **********\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: True\n",
            "Title: Guillaume Tabard: «Pour le budget, une commission mixte paritaire “conclusive” ne conclut rien»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Élections législatives 2024 : tout comprendre au scrutin\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Geoffroy Boulard (LR): «Une vraie réforme, ce n’est pas une modification de loi électorale à Paris-Lyon-Marseille»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Gorarécap Game of Thrones saison 8 épisode 5\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Super Bowl : « Le monde est en train de guérir », jubile Donald Trump après les huées envers Taylor Swift\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Pour redorer son image, le SNU change de nom et devient la « Jeunesse Macronienne »\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Le Conseil de Paris débat du remplacement des vitraux de Notre-Dame et ne prend pas position\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Droit du sol : François Bayrou veut «un débat public approfondi»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Le Covid 19 jaloux de la couverture médiatique accordée à Éric Zemmour\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: True\n",
            "Title: Les syndicats proposent que les négociations pour la réforme des retraites soient remplacées par un combat en octogone\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: True\n",
            "Title: Après une séance d’hypnose, François Bayrou découvre qu’il était un yaourt dans une vie antérieure\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: «Il faut tout reconstruire» : après le budget, François Bayrou veut s’attaquer à la «réforme de l’État»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Les députés En Marche annoncent qu’ils vont désormais lire les propositions de lois avant de les voter\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Festival de Gérardmer : le Canadien Chris Nash récompensé pourIn a violent nature\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Commémorations d’Auschwitz : l'enseignement de la Shoah doit pouvoir être abordé «sans aucune censure», selon Borne\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Test : quel cadeau de Noël raté êtes-vous ?\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: L’international, un domaine que François Bayrou ne se presse pas d’investir\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: LR : un congrès envisagé le 17 mai pour désigner le président\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Accusé “d’agir en mafieux”, Cyril Hanouna met une tête de cheval dans le slip du directeur de l’ARCOM\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: “La démission d’Emmanuel Macron” à nouveau en tête des listes au Père Noël des Français\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Désignation du candidat à la présidentielle, changement de nom du parti, démocratie directe... Le plan de Wauquiez pour relancer la droite\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Il a hâte de lire les critiques du film qu’il vient de voir pour savoir s’il l’a aimé\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Macron confie à Johnny qu’il a toujours été un grand fan des « Lacs du Connemara »\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Mort d’Elias : Valérie Pécresse et Rachida Dati réclament une police municipale armée à Paris\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: False\n",
            "Title: Guillaume Tabard : «Leadership et alliances, des questions à ne pas éluder chez les Républicains»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Brady Corbet, réalisateur deThe Brutalist: « Trump et les autocrates du monde entier ont une façon étrange de romantiser les années 1950 »\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: «C’était un endroit social très important quand j’étais gosse»: pour Antoine Chevrollier,La Pampaest en Anjou\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: L’écriture peut-elle guérir les blessures ?\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: False\n",
            "Title: Emmanuel Macron annonce la dissolution du Nouveau Front Populaire et du Rassemblement National\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: L’Assemblée nationale repousse une troisième motion de censure sur le budget de la Sécurité sociale\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Présidentielle US : Les votes par télégramme seront décomptés d’ici décembre 2022\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Bernar Pivo e dcd\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: «Une libération et un accablement» : les difficiles adieux de Thierry Malandain au Ballet de Biarritz\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Nicolas Florian, ancien maire de Bordeaux et chef de file de l’opposition de droite, est mort\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: En réponse au lisier versé, le gouvernement déverse Amélie Oudéa-Castéra sur les agriculteurs\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Ce qu’il fallait retenir de l’allocution d’Emmanuel Macron\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: Richard Ferrand à la tête du Conseil constitutionnel : Laurent Wauquiez juge que ce profil «pose problème»\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Mort de l’interprète de Dark Vador : David Prowse sera incinéré par un rayon de laser pulvérisant la Terre\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: God Save The Tuche: un cinquième volet de trop ou le meilleur de la franchise ?\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Christine Angot\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: True\n",
            "Title: 5 choses à savoir sur le nouveau Premier ministre Gabriel Attal\n",
            "Predicted is_gorafi: 1 | Actual is_gorafi: True\n",
            "Title: «Qu’il paye les millions d’euros qu’il doit à la France» : Sébastien Chenu répond au président algérien Tebboune\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Title: Fin de vie : Catherine Vautrin s’oppose à François Bayrou et défend un seul texte\n",
            "Predicted is_gorafi: 0 | Actual is_gorafi: False\n",
            "Accuracy =  0.89\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, TrainingArguments, Trainer\n",
        "\n",
        "SEED=42\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"csv\", data_files=\"is-it-gorafi/dataset.csv\")\n",
        "dataset = dataset.map(lambda x: {\"is_gorafi\": int(x[\"is_gorafi\"])})\n",
        "\n",
        "# Split train/test data\n",
        "train_test_split = dataset[\"train\"].train_test_split(test_size=0.2, seed=SEED, shuffle=True)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Geotrend/distilbert-base-en-fr-cased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Geotrend/distilbert-base-en-fr-cased\")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"title\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_datasets = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test_datasets = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Rename label column\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"is_gorafi\", \"label\")\n",
        "tokenized_test_datasets = tokenized_test_datasets.rename_column(\"is_gorafi\", \"label\")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=20,\n",
        "    learning_rate=2e-5,  # Reduced learning rate\n",
        "    weight_decay=0.1,  # L2 regularization\n",
        "    per_device_train_batch_size=32,  # Increase batch size\n",
        "    #load_best_model_at_end=True,  # Load best model based on validation metrics\n",
        "    greater_is_better=True,  # If True, selects the model with highest accuracy\n",
        "    report_to=\"none\",  # Disable logging to Weights & Biases\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_test_datasets\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "\n",
        "# Initialize the sentiment analysis pipeline\n",
        "nlp_ara = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Process dataset\n",
        "def analyze_sentiment(batch):\n",
        "    titles = batch['title']\n",
        "    predictions = nlp_ara(titles)  # Run sentiment analysis on the batch of titles\n",
        "\n",
        "    # Prepare the output\n",
        "    predicted_is_gorafi = [1 if prediction['label'] == 'LABEL_1' else 0 for prediction in predictions]\n",
        "\n",
        "    # Return the batch with the added 'predicted_is_gorafi' field\n",
        "    return {'predicted_is_gorafi': predicted_is_gorafi}\n",
        "\n",
        "# Apply the sentiment analysis function to the dataset\n",
        "test_dataset = test_dataset.map(analyze_sentiment, batched=True)\n",
        "\n",
        "nb_examples = min(100, len(test_dataset))\n",
        "accuracy = 0\n",
        "\n",
        "# Show some results - accessing the first few entries correctly\n",
        "for i in range(nb_examples):  # Show the first 5 examples\n",
        "    example = test_dataset[i]  # Access each example\n",
        "    print(f\"Title: {example['title']}\")\n",
        "    print(f\"Predicted is_gorafi: {example['predicted_is_gorafi']} | Actual is_gorafi: {example['is_gorafi']}\")\n",
        "    if example['predicted_is_gorafi'] == example['is_gorafi']:\n",
        "      accuracy+=1\n",
        "\n",
        "print(\"Accuracy = \", accuracy / nb_examples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-nfsWKLYoGu"
      },
      "source": [
        "## Using our model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix"
      ],
      "metadata": {
        "id": "c2KXQzM3PxEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77fBym3MNVj2",
        "outputId": "2701538b-43f3-4415-db17-4cdc6fbf6371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[257  37]\n",
            " [ 52 289]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Extract true labels and predictions\n",
        "true_labels = [example['is_gorafi'] for example in test_dataset]\n",
        "predicted_labels = [example['predicted_is_gorafi'] for example in test_dataset]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFgUotMFYxZw"
      },
      "source": [
        "### Using model with a sentence provided by us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtbISmoXWZar",
        "outputId": "f6fdc90c-e63d-4a57-a629-2908df490ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: François Durovray favorable à des «peines planchers» en cas d'attaque envers les forces de l'ordre\n",
            "Predicted is_gorafi: 0 with confidence score: 0.9889334440231323\n"
          ]
        }
      ],
      "source": [
        "test_title = \"François Durovray favorable à des «peines planchers» en cas d'attaque envers les forces de l'ordre\"\n",
        "prediction = nlp_ara(test_title)\n",
        "\n",
        "# Check confidence score and adjust prediction logic\n",
        "label = prediction[0]['label']\n",
        "score = prediction[0]['score']\n",
        "\n",
        "if score < 0.6:  # Set a threshold for confidence score\n",
        "    predicted_is_gorafi = 0  # If confidence is low, treat it as not is_gorafi\n",
        "else:\n",
        "    predicted_is_gorafi = 1 if label == 'LABEL_1' else 0\n",
        "\n",
        "print(f\"Title: {test_title}\")\n",
        "print(f\"Predicted is_gorafi: {predicted_is_gorafi} with confidence score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa9rRlVRY4rJ"
      },
      "source": [
        "## Exporting our tokenizer and model in ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbAhd_CPDz2N",
        "outputId": "85e356a3-6bd1-4cfb-89e8-a6756727a798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX model exported to onnx_model/\n"
          ]
        }
      ],
      "source": [
        "from optimum.exporters.onnx import main_export\n",
        "\n",
        "onnx_output_dir = \"onnx_model\"\n",
        "\n",
        "main_export(\n",
        "    model_name_or_path=\"test_trainer/checkpoint-357\",\n",
        "    task=\"text-classification\",\n",
        "    output=onnx_output_dir,\n",
        ")\n",
        "print(f\"ONNX model exported to {onnx_output_dir}/ folder\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_-nfsWKLYoGu"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d3350fefd4141959be4cd3ea6a955e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_038dd84879af49209f6665e793b3b829",
              "IPY_MODEL_9e85525e5b4149e0b86b5f6cebb93704",
              "IPY_MODEL_66cea97b103044de911babb847e8e136"
            ],
            "layout": "IPY_MODEL_f5faf2217894402ca0165c9ca50ca00f"
          }
        },
        "038dd84879af49209f6665e793b3b829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f5637fad4c84226896fe1504027851d",
            "placeholder": "​",
            "style": "IPY_MODEL_4974304de9be4d7881f1b55ac60a2051",
            "value": "Map: 100%"
          }
        },
        "9e85525e5b4149e0b86b5f6cebb93704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_795a6d5b67a94cdb8eb616b0b3e48311",
            "max": 318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_316b4fe38b244c95bee618976ebd3d9f",
            "value": 318
          }
        },
        "66cea97b103044de911babb847e8e136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e746325e7a624edb83eb05092bfbe1f5",
            "placeholder": "​",
            "style": "IPY_MODEL_7403c689ec494344a26ad2fb20f6706c",
            "value": " 318/318 [00:01&lt;00:00, 213.56 examples/s]"
          }
        },
        "f5faf2217894402ca0165c9ca50ca00f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5637fad4c84226896fe1504027851d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4974304de9be4d7881f1b55ac60a2051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "795a6d5b67a94cdb8eb616b0b3e48311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316b4fe38b244c95bee618976ebd3d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e746325e7a624edb83eb05092bfbe1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7403c689ec494344a26ad2fb20f6706c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}